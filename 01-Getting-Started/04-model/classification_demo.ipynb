{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>0</td>\n",
       "      <td>尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>0</td>\n",
       "      <td>盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>0</td>\n",
       "      <td>看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1         1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2         1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3         1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4         1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风\n",
       "...     ...                                                ...\n",
       "7761      0  尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...\n",
       "7762      0  盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...\n",
       "7763      0  看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...\n",
       "7764      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...\n",
       "\n",
       "[7766 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./ChnSentiCorp_htl_all.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>0</td>\n",
       "      <td>尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>0</td>\n",
       "      <td>盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>0</td>\n",
       "      <td>看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1         1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2         1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3         1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4         1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风\n",
       "...     ...                                                ...\n",
       "7761      0  尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...\n",
       "7762      0  盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...\n",
       "7763      0  看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...\n",
       "7764      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...\n",
       "\n",
       "[7765 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 创建Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv('./ChnSentiCorp_htl_all.csv')\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]['review'], self.data.iloc[index]['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', 1)\n",
      "('商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', 1)\n",
      "('早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。', 1)\n",
      "('宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小，但加上低价位因素，还是无超所值的；环境不错，就在小胡同内，安静整洁，暖气好足-_-||。。。呵还有一大优势就是从宾馆出发，步行不到十分钟就可以到梅兰芳故居等等，京味小胡同，北海距离好近呢。总之，不错。推荐给节约消费的自助游朋友~比较划算，附近特色小吃很多~', 1)\n",
      "('CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风', 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset()\n",
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6989, 776)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "trainset, validset = random_split(dataset, lengths=[0.9, 0.1])\n",
    "len(trainset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('交通便利,位于市中心;设置齐备,有车库.不足处是临街隔音效果太差,建议用双层窗户,其次为过道隔音不好,建议能都铺上厚点的地毯．总体而言，这家酒店性价比还可以．', 1)\n",
      "('酒店不错,离我要公干的地方很近.房间设施很好,服务也很好,物有所值.', 1)\n",
      "('早餐还可以，停车方便，二楼餐厅很安静。朝南的房间靠近锅炉房，声音吵。宾馆反馈2008年8月12日：回复：尊敬的宾客：首先非常感谢您对本酒店的肯定。关于您反映的房间外噪音问题，是酒店一项临时性的施工引起，我们对施工的噪音已有具体的要求和措施，也将更加严格执行。诚挚欢迎您的再次光临！', 1)\n",
      "('这次定的是B区的标间，浴室比A区的标间多了浴缸，而且稍大，但房间设施虽然干净但毕竟只能够得上3星。好在早餐不错，可以加分，外加室外的环境真的不错，早起散步感觉很好。在安吉据说这里仍是最好的宾馆，看看每天那么多团体住客就能说明问题了。', 1)\n",
      "('周边环境不好，虽然在五环边上，但交通也不十分便捷，初次去，恐怕不太好找。不过酒店本身还不错，挺新的，停车也很方便。由于只住了一晚，就匆匆离开了，对服务什么的，没太深切的感受。总体感觉还不错。', 1)\n",
      "('靠近路边的房间太吵太吵了，根本没有办法睡觉。劝大家千万不要去了。', 0)\n",
      "('这家酒店是我帮巴西客人订的，据客人说还不错，而且到机场也很方便。', 1)\n",
      "('房间太小。设施太简单。服务太冷淡。不会再住。', 0)\n",
      "('酒店太旧了，价格偏高，所谓送的三餐没有什么优势可言，总要出门办事，不可能天天跑回酒店去吃中餐和晚餐', 1)\n",
      "('和LP一起订的度假，发现三合比较紧俏，于是赶紧下了订单。在三合感觉中国人绝对是“少数民族”估计老外对这个酒店可能比较熟悉，早餐是在酒店外（第一次这种体会，呵呵），出门向左50米（路对面），叫阳光和酒吧。只有第二天早上看到一对中国人，其他全是老外，感觉有点奇怪。早餐内容太少了。酒店内比较别致，很有古城的味道，房间内的家具比较紧凑，不过两个人住应该还好了。热水似乎不行，放了很长时间都是温水。电视奇高无比，晚上看会电视脖子酸，信号也一般。不过如果是体验古城味道，的确是个不错的选择。', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(trainset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 创建Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('../../models/rbt3/')\n",
    "\n",
    "def collate_func(batch):\n",
    "    texts, labels = [], []\n",
    "    for item in batch:\n",
    "        texts.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    inputs = tokenizer(texts, max_length=12, padding='max_length', truncation=True,return_tensors='pt')\n",
    "    inputs['labels'] = torch.tensor(labels)\n",
    "    return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_func)\n",
    "validloader = DataLoader(validset, batch_size=64, shuffle=False, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3146,   860,   677,  2697,  6230,  6820,   679,  7231,  8024,\n",
       "           678,   102],\n",
       "        [  101,  2791,  7313,  1377,   809,   117,  4294,  1166,  4638,  1947,\n",
       "          2791,   102],\n",
       "        [  101,  6858,  6814,  3025,  4923,  7564,  2137,  4638,  6983,  2421,\n",
       "           117,   102],\n",
       "        [  101,  6983,  2421,  4696,  4638,   679,  2582,   720,  3416,  8024,\n",
       "           679,   102],\n",
       "        [  101,  6983,  2421,  4638,   855,  5390,  2523,  1962,   117,  2218,\n",
       "          1762,   102],\n",
       "        [  101,  2600,  1378,  3302,  1218,  1447,   794,  2769,  3341,  1168,\n",
       "          6624,   102],\n",
       "        [  101,   769,  6858,  6820,  1377,   809,  8024,  2802,  6756,  4638,\n",
       "          6413,   102],\n",
       "        [  101,  1157,  1343,  4638,  3198,   952,  3300,  4157,  7410,  2823,\n",
       "           117,   102],\n",
       "        [  101,  3680,  3613,  1168,  2382,  2336,  6963,  3221,   857,  6821,\n",
       "           702,   102],\n",
       "        [  101,  6983,  2421,  2899,  4277,   123,  3215,  8024,   852,  4802,\n",
       "          2141,   102],\n",
       "        [  101,  6821,  2157,  6983,  2421,   809,  1184,  3313,  6230,  2533,\n",
       "          3300,   102],\n",
       "        [  101,  2899,  4638,  3221,   676,  3215,  4638,  4277,  4277,  8024,\n",
       "           852,   102],\n",
       "        [  101,  3302,  1218,  4638,  2578,  2428,  6820,  1377,   809,  8024,\n",
       "          1372,   102],\n",
       "        [  101,  4895,  3322,  1767,  5050,  3221,  3683,  6772,  6818,  4638,\n",
       "          6983,   102],\n",
       "        [  101,  6370,  4638,  3403,  2791,  3766,   749,  8024,  6983,  2421,\n",
       "          5314,   102],\n",
       "        [  101,  2791,  7313,   671,  5663,  1416,  8024,  1310,  4495,  7313,\n",
       "          4638,   102],\n",
       "        [  101,  7478,  2382,  1962,  8013,   671,  6822,  2791,  7313,  2218,\n",
       "          5543,   102],\n",
       "        [  101,  4917,   868,   125,  3215,  8024,  3300,  4157,  4293,  2487,\n",
       "          8024,   102],\n",
       "        [  101,  4384,  1862,  1469,  2791,  7313,  6820,  1377,   809,   117,\n",
       "           817,   102],\n",
       "        [  101,  6983,  2421,  4495,  2692,  3926,  3909,  8024,  1920,  1828,\n",
       "          7027,   102],\n",
       "        [  101,  2791,  7313,  3221,   791,  2399,  3173,  6163,  4638,  8024,\n",
       "          2523,   102],\n",
       "        [  101,  1157,   794,   736,  1290,  2255,  1726,  3341,  8024,   794,\n",
       "          3025,   102],\n",
       "        [  101,  4384,  1862,  7478,  2382,  2406,  7474,  8024,  2769,   812,\n",
       "          1343,   102],\n",
       "        [  101,  3025,  4923,  4638,   817,  3419,  1469,  6983,  2421,  1184,\n",
       "          1378,   102],\n",
       "        [  101,   124,  3299,  8110,  3189,  1057,   857,   511,   817,  3419,\n",
       "          3175,   102],\n",
       "        [  101,  6821,  3221,  2769,  6224,  6814,  3297,  1796,  1769,  4638,\n",
       "          1963,   102],\n",
       "        [  101,  2791,  7313,   722,  7313,  4638,  7392,  7509,  2141,  1762,\n",
       "          3300,   102],\n",
       "        [  101,  3173,  1290,  6983,  2421,  6392,  3177,  7970,  1059,  8024,\n",
       "          1765,   102],\n",
       "        [  101,  6983,  2421,  4638,  6392,  3177,  1469,  3302,  1218,   680,\n",
       "          2989,   102],\n",
       "        [  101,   855,  5390,   831,  6632,   510,  2791,  7313,  1920,  3698,\n",
       "           510,   102],\n",
       "        [  101,  7239,  3736,  6586,  2161,  3517,  2769,  2347,  5307,  1057,\n",
       "           857,   102],\n",
       "        [  101,  6983,  2421,  4802,  2141,   817,  6631,  2792,   966,   117,\n",
       "          2769,   102],\n",
       "        [  101,  2769,  3221,   126,  3299,   129,  3189,  1168,   130,  3189,\n",
       "          2137,   102],\n",
       "        [  101,  6983,  2421,  1765,  3175,  2523,   974,  8024,  1762,   671,\n",
       "           702,   102],\n",
       "        [  101,   671,  2157,   679,  7231,  4638,  2161,  7667,   119,  1372,\n",
       "          3221,   102],\n",
       "        [  101,  6983,  2421,  1762,  7900,  2275,  1062,  1736,  7353,  6818,\n",
       "          8024,   102],\n",
       "        [  101,   677,   671,  3613,  1762,  2548,  2336,   857,  4638,  3221,\n",
       "          2168,   102],\n",
       "        [  101,  2697,  6230,   671,  5663,  8024,  1963,  3362,  3221,  3341,\n",
       "          3180,   102],\n",
       "        [  101,  2218,  8029,  9163,  9414,  4638,   817,   855,  3341,  6432,\n",
       "          6820,   102],\n",
       "        [  101,  6821,  6983,  2421,  1922,  7946,  8024,  6206,  3724,  2458,\n",
       "          6858,   102],\n",
       "        [  101,  2791,  7313,  6392,  3177,   679,  7231,   117,  3302,  1218,\n",
       "          3766,   102],\n",
       "        [  101,   857,  1962,  1126,   702,  3755,  7345,  4638,  6983,  2421,\n",
       "           749,   102],\n",
       "        [  101,  2791,  7313,  2207,   117,  2697,  6230,  1310,  4495,   679,\n",
       "          1922,   102],\n",
       "        [  101,  2791,  7313,   679,  7231,  8024,  2215,  1071,  3221,  2414,\n",
       "           671,   102],\n",
       "        [  101,  2769,  3221,  5018,   671,  3613,   857,  1062,  2171,  2466,\n",
       "          4638,   102],\n",
       "        [  101,  1728,   711,  2145,  2787,  2218,  1762,  3178,  6804,   671,\n",
       "          3406,   102],\n",
       "        [  101,   122,   117,  2791,  7313,  2207,   123,  8024,  2791,  7313,\n",
       "          6858,   102],\n",
       "        [  101,   769,  6858,   912,  1164,  8024,   794,  6983,  2421,  1343,\n",
       "          1920,   102],\n",
       "        [  101,  6983,  2421,  2523,  3191,  8024,  3302,  1218,  2523,   671,\n",
       "          5663,   102],\n",
       "        [  101,  2791,  7313,  3221,  5439,   749,  4157,  8024,   679,  6814,\n",
       "          6392,   102],\n",
       "        [  101,  8108,  3517,  1469,  8149,  3517,  3221,  1398,  3416,  4638,\n",
       "           817,   102],\n",
       "        [  101,  1762,   673,  3299,   819,  8024,  2769,  1385,  2145,  2787,\n",
       "          1066,   102],\n",
       "        [  101,  7345,  1045,  6983,  2421,  3683,  2769,  2682,  6496,   704,\n",
       "          6206,   102],\n",
       "        [  101,  1920,   860,  2697,  6230,   679,  7231,  8024,  4384,  1862,\n",
       "           738,   102],\n",
       "        [  101,  5018,   671,  3613,  1057,   857,  8024,  2697,  6230,  6983,\n",
       "          2421,   102],\n",
       "        [  101,  6421,  6983,  2421,  3221,  3025,  4923,  2792,   792,  5305,\n",
       "          4638,   102],\n",
       "        [  101,   809,   711,  1469,  3946,  2336,  4638,  1290,   905,  7649,\n",
       "          2421,   102],\n",
       "        [  101,  5307,  3845,  2141,  2669,  8024,  2791,  7313,  3688,  2353,\n",
       "           679,   102],\n",
       "        [  101,  2014,  3862,  1394,  2412,  7649,  2421,  4638,  3302,  1218,\n",
       "          4294,   102],\n",
       "        [  101,  8174, 10911,  8640, 12742,  8783,  8472,  8277, 11595,  8181,\n",
       "         11202,   102],\n",
       "        [  101,  6821,  3221,  2769,   857,  6814,  4638,  3297,  5552,  4638,\n",
       "          2421,   102],\n",
       "        [  101,  6983,  2421,  3302,  1218,   679,  7231,  8024,  4384,  1862,\n",
       "           738,   102],\n",
       "        [  101,  1168,  6809,  5305,  1069,  1400,  8024,  1372,  6206,  5314,\n",
       "          6821,   102],\n",
       "        [  101,  6858,  6814,  3025,  4923,  2137,   749, 10468,  1039,   676,\n",
       "          7313,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(validloader))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 创建模型及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 11:59:29.351314: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-13 11:59:29.388407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-13 11:59:30.184005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../../models/rbt3/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../../models/rbt3/')\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k, v in batch.items()}\n",
    "\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch['labels'].long()).float().sum()\n",
    "\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "\n",
    "def train(epoch=10, log_step=100):\n",
    "    global_step = 0\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if global_step % log_step == 0:\n",
    "                print(f'ep : {ep}, global_step: {global_step}, loss: {output.loss.item()}')\n",
    "            global_step += 1\n",
    "\n",
    "        acc = evaluate()\n",
    "        print(f'ep: {ep}, acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep : 0, global_step: 0, loss: 0.3042250871658325\n",
      "ep : 0, global_step: 100, loss: 0.3266545534133911\n",
      "ep : 0, global_step: 200, loss: 0.3254771828651428\n",
      "ep: 0, acc: 0.7886597514152527\n",
      "ep : 1, global_step: 300, loss: 0.3195094168186188\n",
      "ep : 1, global_step: 400, loss: 0.25848037004470825\n",
      "ep: 1, acc: 0.7847937941551208\n",
      "ep : 2, global_step: 500, loss: 0.30616986751556396\n",
      "ep : 2, global_step: 600, loss: 0.11087875068187714\n",
      "ep: 2, acc: 0.7706185579299927\n",
      "ep : 3, global_step: 700, loss: 0.20774158835411072\n",
      "ep : 3, global_step: 800, loss: 0.06977453827857971\n",
      "ep: 3, acc: 0.7654638886451721\n",
      "ep : 4, global_step: 900, loss: 0.45530325174331665\n",
      "ep : 4, global_step: 1000, loss: 0.0937582403421402\n",
      "ep: 4, acc: 0.7603092789649963\n",
      "ep : 5, global_step: 1100, loss: 0.02936185896396637\n",
      "ep : 5, global_step: 1200, loss: 0.020834796130657196\n",
      "ep : 5, global_step: 1300, loss: 0.08647172152996063\n",
      "ep: 5, acc: 0.7719072103500366\n",
      "ep : 6, global_step: 1400, loss: 0.03320871293544769\n",
      "ep : 6, global_step: 1500, loss: 0.21887001395225525\n",
      "ep: 6, acc: 0.7744845151901245\n",
      "ep : 7, global_step: 1600, loss: 0.07100630551576614\n",
      "ep : 7, global_step: 1700, loss: 0.031390465795993805\n",
      "ep: 7, acc: 0.7757731676101685\n",
      "ep : 8, global_step: 1800, loss: 0.029886052012443542\n",
      "ep : 8, global_step: 1900, loss: 0.20777082443237305\n",
      "ep: 8, acc: 0.7641752362251282\n",
      "ep : 9, global_step: 2000, loss: 0.01786099188029766\n",
      "ep : 9, global_step: 2100, loss: 0.018915489315986633\n",
      "ep: 9, acc: 0.780927836894989\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: 我觉得这家酒店不错，饭很好吃！\n",
      "模型预测结果: 好评！\n"
     ]
    }
   ],
   "source": [
    "sen = '我觉得这家酒店不错，饭很好吃！'\n",
    "id2label = {0: '差评！', 1:'好评！'}\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt')\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "    print(f'输入: {sen}\\n模型预测结果: {id2label.get(pred.item())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.config.id2label = id2label\n",
    "pipe = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '好评！', 'score': 0.9999101161956787}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
