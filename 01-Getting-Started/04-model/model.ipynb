{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型加载与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Envs\\py_cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在线加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 828/828 [00:00<00:00, 1.61MB/s]\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jone\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 828/828 [00:00<?, ?B/s] \n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Envs\\py_cuda\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Downloading pytorch_model.bin: 100%|██████████| 156M/156M [01:13<00:00, 2.13MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('hfl/rbt3', force_download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'rbt3'...\n",
      "Updating files:  63% (7/11)\n",
      "Updating files:  72% (8/11)\n",
      "Updating files:  81% (9/11)\n",
      "Updating files:  90% (10/11)\n",
      "Updating files: 100% (11/11)\n",
      "Updating files: 100% (11/11), done.\n",
      "Filtering content:  66% (2/3)\n",
      "Filtering content:  66% (2/3), 442.86 MiB | 227.89 MiB/s\n",
      "Filtering content: 100% (3/3), 442.86 MiB | 227.89 MiB/s\n",
      "Filtering content: 100% (3/3), 442.86 MiB | 3.67 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone \"https://huggingface.co/hfl/rbt3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
      "          with new flags from 'git clone'\n",
      "\n",
      "'git clone' has been updated in upstream Git to have comparable\n",
      "speeds to 'git lfs clone'.\n",
      "Cloning into 'rbt3'...\n"
     ]
    }
   ],
   "source": [
    "!git lfs clone \"https://huggingface.co/hfl/rbt3\" --include=\"*.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 离线加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('./rbt3/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"./rbt3/\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('./rbt3/')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.configuration_bert.BertConfig"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 3457, 2682,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '弱小的我也有大梦想!'\n",
    "tokenizer = AutoTokenizer.from_pretrained('rbt3')\n",
    "inputs = tokenizer(sen, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('rbt3', output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2303,  0.1315,  0.6920,  ..., -0.5849,  0.5341, -0.0374],\n",
       "         [-0.7454, -0.3422,  0.5117,  ..., -0.0404, -0.4554, -0.6653],\n",
       "         [-0.0628,  0.6292,  0.1078,  ..., -0.3379,  0.3596, -0.5689],\n",
       "         ...,\n",
       "         [ 0.1060,  0.6700, -0.0908,  ..., -0.1800,  0.2782,  0.2195],\n",
       "         [ 0.1642,  0.0029,  0.0420,  ..., -0.5950, -0.2168, -0.5789],\n",
       "         [ 0.2265,  0.1351,  0.6900,  ..., -0.5835,  0.5320, -0.0330]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.1423e-01, -9.9031e-01, -1.0000e+00, -9.0013e-01,  9.9648e-01,\n",
       "         -2.0447e-02,  3.6240e-01, -1.3737e-01,  9.9396e-01,  9.9986e-01,\n",
       "         -1.0428e-02, -1.0000e+00,  6.2199e-02,  9.9932e-01, -9.9999e-01,\n",
       "          9.9966e-01,  9.9652e-01,  9.5564e-01, -9.9572e-01, -4.5835e-02,\n",
       "         -9.7243e-01, -9.9092e-01,  9.6289e-02,  9.4169e-01,  9.9111e-01,\n",
       "         -9.9721e-01, -9.9998e-01,  2.0293e-02, -7.7725e-01, -9.9986e-01,\n",
       "         -9.9750e-01, -9.9991e-01,  4.3620e-01, -1.7561e-01,  9.8662e-01,\n",
       "         -9.9125e-01,  9.1909e-03, -9.8745e-01, -9.9951e-01, -9.9751e-01,\n",
       "         -1.1877e-01,  9.8419e-01, -9.9008e-02,  9.9979e-01, -3.2069e-02,\n",
       "          3.6571e-04,  9.9997e-01,  9.2821e-01, -8.5779e-02,  7.8173e-01,\n",
       "         -3.7467e-02, -2.5138e-01, -9.8703e-01,  9.9655e-01,  1.7046e-01,\n",
       "          6.7737e-02,  9.9848e-01, -1.0000e+00, -9.9979e-01,  9.9424e-01,\n",
       "         -9.9991e-01,  9.8921e-01,  9.9753e-01,  9.9579e-01, -6.7433e-01,\n",
       "          9.9986e-01,  9.9960e-01,  9.7124e-01, -3.6567e-01, -1.0000e+00,\n",
       "          6.0533e-01, -8.9727e-01, -9.9980e-01, -7.5754e-02, -3.6908e-01,\n",
       "         -9.9974e-01,  9.8859e-01, -1.2817e-01,  9.9994e-01,  2.4102e-01,\n",
       "         -9.9988e-01,  1.2390e-01,  2.1912e-01, -1.8849e-01,  9.9952e-01,\n",
       "          9.9998e-01,  1.9906e-01, -9.4688e-01,  1.0301e-01, -9.9442e-01,\n",
       "         -5.8447e-02,  9.9839e-01,  9.9956e-01, -9.9995e-01,  9.9986e-01,\n",
       "         -8.4632e-01,  6.2535e-02,  2.1701e-01, -9.9740e-01,  9.9681e-01,\n",
       "          3.0388e-02, -8.3942e-02,  1.0000e+00,  9.9927e-01,  9.5750e-02,\n",
       "         -9.9983e-01, -9.9382e-01,  9.9979e-01, -9.9657e-01,  3.0075e-02,\n",
       "          1.0000e+00,  9.5146e-01,  1.0000e+00,  9.9592e-01,  9.9995e-01,\n",
       "         -9.9995e-01, -5.3494e-01,  2.4040e-01, -9.9994e-01,  9.9871e-01,\n",
       "         -9.9270e-01, -7.1938e-02, -8.9010e-01, -4.8603e-02, -1.8072e-02,\n",
       "         -9.9989e-01,  2.0437e-01,  6.3928e-02, -9.9592e-01, -9.9755e-01,\n",
       "         -9.9972e-01, -9.9978e-01,  9.8786e-01,  7.2808e-01,  7.9491e-01,\n",
       "         -3.0777e-01,  1.1914e-01, -3.7539e-02, -9.9999e-01, -9.9991e-01,\n",
       "         -9.9980e-01,  8.1880e-02, -5.7780e-01,  9.9700e-01, -9.9927e-01,\n",
       "          9.9967e-01, -9.9956e-01,  9.9996e-01,  9.7309e-01,  7.3906e-02,\n",
       "         -2.1625e-01,  2.0424e-01, -9.9989e-01,  1.2890e-01, -3.9629e-03,\n",
       "          9.7699e-01,  9.9793e-01,  9.6015e-01, -7.8420e-01,  9.9999e-01,\n",
       "         -9.9147e-01,  9.8136e-01, -1.4564e-01,  9.9577e-01,  1.0000e+00,\n",
       "         -9.9999e-01,  2.1295e-01, -1.0000e+00,  6.2691e-01,  1.3894e-01,\n",
       "          9.9995e-01,  9.9891e-01,  9.8498e-01,  9.9985e-01, -6.8542e-01,\n",
       "         -9.9987e-01,  8.8739e-01, -9.9998e-01,  9.5015e-01,  1.0000e+00,\n",
       "          4.6266e-03,  3.2129e-01,  1.0000e+00, -5.9645e-01,  9.9813e-01,\n",
       "         -2.0156e-01, -2.9964e-01, -9.9914e-01,  3.3461e-01,  8.9895e-01,\n",
       "          9.9212e-01, -9.9463e-01, -1.9624e-01,  9.7323e-01,  1.5653e-01,\n",
       "         -9.6298e-02, -9.9962e-01, -9.9975e-01,  9.9989e-01,  9.9975e-01,\n",
       "          4.5567e-01, -2.0016e-01,  1.0000e+00, -1.5748e-01,  9.9915e-01,\n",
       "         -3.3018e-02,  6.8961e-01, -4.1225e-01,  9.9685e-01,  1.7816e-01,\n",
       "          9.3496e-01, -1.9615e-02,  9.9995e-01, -6.0776e-01, -9.9998e-01,\n",
       "         -7.8656e-02,  8.3049e-01,  3.1642e-01, -9.9635e-01,  7.7207e-01,\n",
       "         -2.0238e-01,  9.9996e-01,  3.1356e-02, -9.1835e-01,  9.8978e-01,\n",
       "         -9.9982e-01,  7.9441e-01, -1.0000e+00, -9.9772e-01,  9.9997e-01,\n",
       "         -2.7541e-01, -1.0000e+00,  9.2406e-01,  9.9999e-01, -7.5590e-01,\n",
       "          9.9220e-01, -1.5231e-01, -9.9987e-01, -1.1780e-02, -1.8509e-01,\n",
       "         -1.0000e+00, -9.9672e-01, -1.0000e+00, -9.7630e-01,  7.2316e-02,\n",
       "          9.9455e-01, -9.9997e-01,  2.3163e-01, -9.9997e-01,  9.8814e-01,\n",
       "          9.9985e-01, -1.2220e-01, -6.6994e-02,  1.0000e+00, -8.8095e-01,\n",
       "          1.6079e-02, -7.7227e-01,  2.5491e-01, -4.5121e-02,  9.9922e-01,\n",
       "          2.5127e-01,  9.9939e-01, -9.9951e-01,  1.3938e-01,  8.7259e-01,\n",
       "         -9.9999e-01, -3.9651e-01,  9.0505e-01,  9.7466e-02,  8.9700e-02,\n",
       "         -1.6631e-01,  1.1780e-01,  9.4376e-01,  9.9952e-01,  1.0000e+00,\n",
       "          9.9580e-01,  9.9999e-01,  9.9996e-01,  7.0722e-02, -9.9626e-01,\n",
       "         -8.9867e-01, -5.9669e-02, -9.9997e-01, -9.4008e-01, -9.9960e-01,\n",
       "          9.1216e-01, -2.8174e-02,  1.0000e+00, -9.9996e-01,  1.0000e+00,\n",
       "         -9.8351e-01,  1.4915e-01, -4.0514e-02,  2.2060e-01, -2.2618e-01,\n",
       "          1.9434e-02,  9.9732e-01,  2.7006e-01,  9.9523e-01,  9.9610e-01,\n",
       "          4.6832e-02, -2.5259e-01,  3.4687e-01,  2.2398e-02,  9.9915e-01,\n",
       "         -9.9017e-01,  9.9260e-01,  1.0513e-01,  9.9981e-01, -2.7998e-01,\n",
       "         -9.9997e-01,  9.9850e-01, -9.9975e-01, -5.6764e-01, -9.9987e-01,\n",
       "         -9.0746e-01, -1.2986e-01, -9.7773e-01,  3.6548e-01,  9.8719e-01,\n",
       "          1.4649e-01, -5.0313e-01, -9.9999e-01, -9.7025e-01,  9.8289e-01,\n",
       "          9.9984e-01, -9.9968e-01,  9.9961e-01,  9.9530e-01, -8.0382e-01,\n",
       "          4.4686e-01,  9.1437e-01, -9.9868e-01,  9.9568e-01, -9.9999e-01,\n",
       "         -5.1110e-02,  9.8986e-01,  4.5414e-02, -9.9974e-01, -8.9681e-01,\n",
       "         -6.2145e-02,  8.3275e-01, -3.3497e-01,  9.9998e-01, -1.0524e-01,\n",
       "          2.4183e-02, -9.9988e-01, -9.9671e-01, -6.6760e-01,  2.3607e-01,\n",
       "          9.9972e-01, -9.9999e-01, -1.5317e-01,  9.9965e-01, -9.9917e-01,\n",
       "         -3.9945e-01,  4.2683e-02,  2.4764e-01,  1.5103e-01, -9.8458e-01,\n",
       "         -9.9998e-01, -9.9972e-01,  9.9998e-01,  3.4070e-02,  9.3916e-04,\n",
       "          9.9865e-01,  9.9947e-01,  9.9984e-01, -9.9662e-01,  7.1158e-01,\n",
       "          9.9964e-01, -9.9220e-02,  6.7395e-03, -8.2799e-01, -2.1523e-01,\n",
       "         -9.2532e-01, -9.5794e-01,  1.9023e-01, -7.3002e-02, -5.0842e-01,\n",
       "         -9.9735e-01,  9.9995e-01,  9.9996e-01,  1.0000e+00, -2.0374e-01,\n",
       "         -9.2176e-01,  9.7166e-01, -9.4460e-01, -9.9907e-01,  2.1632e-02,\n",
       "          9.9975e-01, -9.9832e-01,  3.1425e-01, -3.1673e-01, -9.2418e-01,\n",
       "          9.9831e-01, -9.9973e-01,  4.2291e-02, -1.0000e+00, -9.9987e-01,\n",
       "         -9.9999e-01,  9.9999e-01,  9.0119e-03, -2.4893e-01, -9.9966e-01,\n",
       "          1.0000e+00,  9.4091e-01, -8.4963e-01, -7.6983e-02,  9.9998e-01,\n",
       "         -5.5818e-01, -8.0490e-01, -9.9999e-01, -9.9929e-01,  9.9763e-01,\n",
       "          7.4765e-02,  9.9997e-01,  1.1886e-01, -9.9556e-01,  6.5835e-01,\n",
       "          9.7758e-01,  7.1586e-02, -9.9859e-01, -9.9925e-01, -9.1608e-02,\n",
       "          1.4678e-01,  1.8939e-02, -3.4638e-01,  9.9880e-02,  9.9985e-01,\n",
       "         -1.0529e-01, -1.0293e-01, -2.8716e-01,  1.0000e+00,  1.0670e-01,\n",
       "         -9.9836e-01, -9.1580e-01, -1.0200e-02, -9.9173e-01, -9.8819e-01,\n",
       "         -9.9964e-01, -2.2784e-01,  1.2937e-01,  8.1569e-02, -9.9114e-01,\n",
       "         -9.9862e-01, -9.9987e-01,  2.6592e-02, -9.2125e-01, -9.5786e-01,\n",
       "         -9.7446e-02, -9.9908e-01, -9.9802e-01,  9.9983e-01, -9.9918e-01,\n",
       "         -4.9590e-02,  9.8576e-01,  9.9857e-01, -9.9975e-01,  1.6821e-01,\n",
       "          9.9605e-01, -9.9547e-01,  3.8661e-01, -9.3498e-01,  1.6443e-01,\n",
       "         -8.8958e-01, -9.9999e-01,  2.2712e-01,  9.9964e-01,  9.9977e-01,\n",
       "          9.9396e-01,  9.6380e-01, -8.9027e-01,  9.8485e-01,  9.9906e-01,\n",
       "          1.0000e+00,  5.1673e-02, -2.6373e-01, -9.9998e-01,  3.9728e-01,\n",
       "          7.9399e-01,  2.2501e-01,  8.7674e-01, -9.9987e-01,  2.6928e-01,\n",
       "          8.3097e-02,  4.8408e-01,  1.0000e+00,  9.7086e-01, -2.1400e-01,\n",
       "         -9.9998e-01,  2.5471e-01, -5.8367e-01,  1.4376e-01, -9.9811e-01,\n",
       "         -3.2228e-02,  9.9999e-01, -9.7899e-01, -1.1673e-01, -9.9970e-01,\n",
       "         -9.9962e-01,  9.9913e-01, -9.9997e-01,  9.9999e-01,  9.8761e-01,\n",
       "         -9.8312e-01, -2.1786e-01, -9.4404e-01,  1.6476e-01, -7.8377e-02,\n",
       "         -2.1348e-01, -3.3061e-02, -1.4732e-01, -1.0000e+00, -1.0362e-01,\n",
       "          9.9008e-01, -4.2999e-02, -8.5791e-01, -9.9962e-01,  1.5769e-01,\n",
       "          9.6397e-01, -9.9951e-01, -9.9989e-01, -1.8917e-01, -3.3693e-01,\n",
       "          3.0375e-01,  4.6081e-01, -2.5111e-02, -1.1940e-01, -9.9532e-01,\n",
       "          1.0050e-01,  9.5858e-01, -8.5981e-01,  8.0105e-01, -8.8529e-01,\n",
       "         -8.7995e-01, -4.0920e-01,  9.9970e-01,  9.9968e-01, -9.9953e-01,\n",
       "         -9.9930e-01, -4.3001e-01, -2.1011e-01, -6.6780e-01,  9.9939e-01,\n",
       "         -1.6166e-01, -9.9799e-01,  9.4045e-02,  7.4077e-02, -2.2685e-01,\n",
       "         -9.0221e-01,  9.9999e-01, -9.9884e-01,  9.9999e-01, -9.9999e-01,\n",
       "         -9.6994e-01,  6.9850e-02,  9.9997e-01, -9.9996e-01, -1.1585e-01,\n",
       "          9.9976e-01, -1.0000e+00, -1.2705e-02, -8.8289e-01,  9.5322e-01,\n",
       "         -1.7014e-01,  2.8415e-03,  8.8737e-01, -9.9982e-01,  4.1860e-02,\n",
       "         -9.9881e-01,  8.4022e-01,  9.8994e-01, -9.9993e-01, -8.9917e-01,\n",
       "         -9.9999e-01, -3.2569e-02,  2.5408e-01, -9.9980e-01,  9.9248e-01,\n",
       "          9.9995e-01, -1.7652e-01,  8.4261e-01, -9.9974e-01,  1.5877e-02,\n",
       "         -1.5681e-01, -9.5609e-01,  8.1283e-02, -9.9975e-01,  7.9970e-01,\n",
       "         -9.9742e-01,  9.8793e-01, -9.9999e-01,  9.5545e-01,  9.9788e-01,\n",
       "         -5.4601e-02,  3.3451e-01,  8.0976e-02,  2.9596e-01, -9.9997e-01,\n",
       "         -2.6638e-01, -9.9989e-01, -9.9928e-01, -1.4753e-01,  9.9983e-01,\n",
       "          9.8910e-01,  2.8043e-01,  9.0300e-01, -9.9826e-01,  2.6603e-01,\n",
       "          3.7326e-01,  9.5292e-01,  9.9999e-01, -9.9972e-01, -9.9790e-01,\n",
       "          9.9867e-01, -9.9990e-01, -9.8824e-01,  1.0000e+00,  4.7893e-01,\n",
       "          9.9984e-01,  7.2271e-07, -9.9786e-01,  7.8437e-03,  8.2751e-02,\n",
       "          9.9903e-01,  7.3887e-02,  5.1389e-03,  9.9996e-01,  3.3746e-03,\n",
       "         -1.2867e-01, -5.2294e-01,  9.8931e-01, -1.8488e-02, -2.1234e-01,\n",
       "          9.9719e-01, -9.4974e-01, -9.9682e-01, -9.9984e-01,  2.0373e-01,\n",
       "         -2.0829e-01, -4.2335e-02, -2.1684e-01, -2.3288e-01,  1.0000e+00,\n",
       "         -9.9964e-01,  9.9043e-01, -1.0000e+00, -9.9998e-01,  1.7319e-01,\n",
       "          3.0125e-01,  9.9982e-01,  2.9269e-02, -9.7909e-01,  6.5295e-02,\n",
       "         -9.6980e-01,  9.9960e-01, -9.9952e-01,  9.0510e-01, -2.2664e-01,\n",
       "          2.4504e-01,  9.9987e-01,  9.9986e-01, -6.6353e-02, -9.9784e-01,\n",
       "         -8.8136e-01,  1.0230e-01, -9.9633e-01,  9.9944e-01, -5.9789e-02,\n",
       "         -1.2536e-01, -1.4865e-01,  8.8100e-03, -9.9975e-01, -9.9541e-01,\n",
       "          1.3488e-01,  9.9670e-01, -9.9994e-01,  5.7086e-01, -9.8252e-01,\n",
       "          9.9953e-01,  9.9983e-01,  1.0000e+00,  4.8897e-02,  9.8796e-01,\n",
       "         -9.9989e-01, -9.7469e-01,  9.9420e-01,  9.9801e-01,  1.0000e+00,\n",
       "          9.9595e-01,  9.8565e-01,  1.6527e-01, -9.9991e-01,  9.6021e-01,\n",
       "          7.1068e-02, -1.2090e-01, -1.9141e-02, -8.5223e-01, -9.9997e-01,\n",
       "          9.9996e-01, -9.9982e-01, -9.9994e-01, -8.4477e-01, -9.9980e-01,\n",
       "          9.9909e-01,  9.6863e-01,  9.9958e-01,  8.7587e-01, -9.9978e-01,\n",
       "         -9.9630e-01, -1.0472e-01, -9.8812e-01, -9.9541e-01,  8.7290e-02,\n",
       "         -1.0000e+00,  1.5372e-01,  2.0267e-01, -9.3297e-01,  8.4060e-04,\n",
       "         -6.4453e-01, -5.6651e-01,  9.9860e-01,  8.0512e-01,  9.3844e-01,\n",
       "         -9.2438e-01, -9.9368e-01,  6.1587e-02, -9.9997e-01,  9.9055e-01,\n",
       "          9.9997e-01, -1.9343e-01,  9.9508e-01, -9.2839e-01,  3.0449e-02,\n",
       "         -9.9998e-01, -1.0000e+00,  9.1229e-01,  9.9970e-01, -8.2262e-03,\n",
       "         -9.9978e-01, -4.7766e-03, -9.9916e-01, -1.0291e-01,  8.9604e-01,\n",
       "          9.9500e-01, -9.9989e-01,  9.9920e-01, -9.0884e-01,  1.9754e-01,\n",
       "          9.2889e-01, -1.0000e+00,  1.5384e-01, -9.6558e-01,  9.9990e-01,\n",
       "         -1.0000e+00,  9.9764e-01, -4.5049e-01,  9.8486e-02, -1.0668e-01,\n",
       "          9.5173e-01, -9.9905e-01, -2.4721e-01,  9.5724e-01,  9.4773e-01,\n",
       "          3.5923e-02,  9.9639e-01,  8.4267e-02]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[4.7834e-01, 3.7083e-04, 1.6192e-04,  ..., 1.4240e-04,\n",
       "           5.3219e-04, 5.1807e-01],\n",
       "          [5.3721e-03, 9.2710e-02, 1.1131e-01,  ..., 1.7965e-01,\n",
       "           4.8387e-02, 4.1866e-03],\n",
       "          [1.9783e-02, 1.1036e-01, 1.9662e-01,  ..., 1.2147e-01,\n",
       "           6.9115e-02, 3.5744e-03],\n",
       "          ...,\n",
       "          [3.0492e-02, 9.5128e-02, 4.9496e-02,  ..., 1.1869e-01,\n",
       "           8.4113e-02, 1.1902e-02],\n",
       "          [8.2355e-02, 4.1253e-02, 3.8168e-02,  ..., 5.6687e-02,\n",
       "           3.6268e-01, 1.7667e-02],\n",
       "          [4.6661e-01, 8.9941e-04, 4.2475e-04,  ..., 2.7240e-04,\n",
       "           1.7427e-03, 5.2686e-01]],\n",
       "\n",
       "         [[9.9049e-01, 2.5787e-05, 2.0246e-04,  ..., 5.2088e-05,\n",
       "           4.7320e-04, 3.7648e-03],\n",
       "          [1.7755e-02, 1.2910e-04, 9.8208e-01,  ..., 2.9791e-10,\n",
       "           9.4334e-06, 2.7123e-07],\n",
       "          [2.1831e-02, 9.7443e-01, 1.5326e-04,  ..., 1.2469e-08,\n",
       "           4.2760e-08, 1.0876e-04],\n",
       "          ...,\n",
       "          [1.1540e-02, 3.0097e-09, 4.1634e-08,  ..., 1.5048e-04,\n",
       "           4.4975e-04, 1.7718e-04],\n",
       "          [1.9802e-01, 7.4362e-07, 6.0349e-08,  ..., 9.0418e-04,\n",
       "           2.3898e-03, 7.9817e-01],\n",
       "          [7.3506e-01, 1.7055e-07, 9.3048e-05,  ..., 3.3006e-05,\n",
       "           2.6043e-01, 3.3181e-03]],\n",
       "\n",
       "         [[1.7321e-01, 9.5756e-02, 2.7027e-02,  ..., 5.9795e-02,\n",
       "           5.2400e-02, 2.4205e-01],\n",
       "          [4.7394e-01, 3.2298e-01, 3.1183e-02,  ..., 8.9935e-03,\n",
       "           1.1787e-02, 9.5471e-02],\n",
       "          [4.9208e-01, 1.7839e-01, 1.9331e-01,  ..., 4.8077e-03,\n",
       "           8.0371e-03, 6.2534e-02],\n",
       "          ...,\n",
       "          [1.5559e-01, 6.1321e-02, 5.8197e-02,  ..., 6.8683e-02,\n",
       "           2.8666e-02, 2.9693e-02],\n",
       "          [1.0103e-01, 3.9205e-02, 1.8210e-02,  ..., 5.7890e-02,\n",
       "           6.4680e-02, 9.0105e-02],\n",
       "          [3.7882e-02, 4.1341e-02, 4.5799e-02,  ..., 8.5826e-02,\n",
       "           1.1145e-01, 1.3153e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7.1682e-01, 2.2299e-02, 4.1183e-02,  ..., 2.4067e-02,\n",
       "           4.7881e-03, 7.6401e-02],\n",
       "          [4.0945e-01, 3.2446e-01, 1.1176e-02,  ..., 1.2541e-02,\n",
       "           7.1993e-03, 1.0556e-01],\n",
       "          [5.8676e-01, 5.5637e-03, 5.4361e-03,  ..., 1.7331e-02,\n",
       "           1.8478e-02, 2.7447e-01],\n",
       "          ...,\n",
       "          [3.7350e-01, 4.4199e-02, 4.9160e-02,  ..., 2.4456e-01,\n",
       "           1.3580e-02, 7.8177e-02],\n",
       "          [1.7424e-01, 1.6886e-02, 3.2328e-02,  ..., 3.4992e-03,\n",
       "           4.0336e-01, 3.0872e-01],\n",
       "          [4.3042e-01, 4.3007e-02, 9.0029e-02,  ..., 1.3622e-02,\n",
       "           1.2170e-02, 1.4254e-01]],\n",
       "\n",
       "         [[9.7346e-01, 5.4130e-03, 3.0839e-03,  ..., 1.6784e-03,\n",
       "           2.4447e-03, 5.4021e-03],\n",
       "          [7.9600e-03, 7.2649e-02, 4.8070e-01,  ..., 4.1841e-03,\n",
       "           2.1373e-03, 6.7617e-03],\n",
       "          [1.4966e-03, 7.2082e-03, 1.7673e-02,  ..., 6.2060e-04,\n",
       "           3.6742e-03, 2.2038e-03],\n",
       "          ...,\n",
       "          [1.8953e-03, 5.4729e-04, 2.0175e-04,  ..., 6.7620e-03,\n",
       "           7.8623e-01, 1.9757e-01],\n",
       "          [1.3731e-02, 7.1529e-04, 4.9900e-04,  ..., 2.0346e-03,\n",
       "           5.3172e-02, 9.2650e-01],\n",
       "          [9.9347e-01, 6.1975e-05, 1.0302e-04,  ..., 2.0505e-04,\n",
       "           7.2576e-04, 5.1241e-03]],\n",
       "\n",
       "         [[4.2145e-01, 2.4257e-02, 1.9583e-02,  ..., 1.5904e-02,\n",
       "           3.2438e-02, 3.2886e-01],\n",
       "          [7.5394e-01, 1.0996e-01, 2.2775e-03,  ..., 4.7667e-03,\n",
       "           1.7848e-02, 6.7890e-03],\n",
       "          [4.3961e-02, 9.3097e-01, 6.5189e-03,  ..., 1.7741e-04,\n",
       "           1.3193e-03, 1.4441e-03],\n",
       "          ...,\n",
       "          [4.3585e-02, 1.1254e-03, 7.6491e-05,  ..., 2.7628e-02,\n",
       "           8.7990e-03, 6.8047e-03],\n",
       "          [1.5646e-01, 3.6810e-03, 4.3112e-03,  ..., 4.2281e-01,\n",
       "           2.0651e-01, 6.5673e-02],\n",
       "          [6.9270e-02, 1.4763e-03, 7.1253e-04,  ..., 2.1531e-02,\n",
       "           4.0508e-01, 4.8836e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.3373e-01, 1.2253e-02, 5.8838e-03,  ..., 7.2982e-03,\n",
       "           6.2432e-02, 4.1684e-01],\n",
       "          [4.9973e-01, 1.3815e-02, 3.0305e-03,  ..., 2.9241e-06,\n",
       "           3.7307e-03, 4.7256e-01],\n",
       "          [1.4983e-02, 9.6942e-01, 1.2130e-05,  ..., 1.7475e-07,\n",
       "           2.9281e-06, 1.4825e-02],\n",
       "          ...,\n",
       "          [5.0416e-02, 8.9785e-06, 4.7017e-06,  ..., 7.9619e-06,\n",
       "           6.0868e-04, 4.8416e-02],\n",
       "          [4.3175e-01, 3.5763e-04, 1.2294e-04,  ..., 9.5789e-02,\n",
       "           2.7656e-02, 4.2955e-01],\n",
       "          [4.3443e-01, 1.1588e-02, 5.7426e-03,  ..., 7.0511e-03,\n",
       "           6.5108e-02, 4.1722e-01]],\n",
       "\n",
       "         [[4.6250e-01, 1.0442e-02, 6.8817e-03,  ..., 6.3403e-03,\n",
       "           1.4660e-02, 4.4631e-01],\n",
       "          [2.8047e-01, 1.3274e-02, 1.1046e-02,  ..., 3.0136e-02,\n",
       "           1.6747e-01, 2.8080e-01],\n",
       "          [2.2855e-01, 2.1633e-02, 8.1959e-03,  ..., 5.9637e-02,\n",
       "           1.9418e-01, 2.2815e-01],\n",
       "          ...,\n",
       "          [2.6848e-01, 1.9827e-02, 1.0813e-02,  ..., 2.9120e-02,\n",
       "           2.8328e-01, 2.6810e-01],\n",
       "          [3.5810e-01, 1.3714e-02, 9.0134e-03,  ..., 3.7893e-02,\n",
       "           1.0678e-01, 3.5412e-01],\n",
       "          [4.6488e-01, 9.7365e-03, 6.4745e-03,  ..., 6.1127e-03,\n",
       "           1.3543e-02, 4.4893e-01]],\n",
       "\n",
       "         [[4.9648e-01, 4.7060e-03, 4.1642e-03,  ..., 1.8010e-03,\n",
       "           2.3434e-03, 4.5042e-01],\n",
       "          [3.9430e-01, 2.2011e-01, 9.8542e-03,  ..., 1.3186e-03,\n",
       "           1.7814e-03, 3.6269e-01],\n",
       "          [3.8118e-01, 1.4269e-01, 9.3725e-02,  ..., 1.0625e-03,\n",
       "           2.3013e-03, 3.5238e-01],\n",
       "          ...,\n",
       "          [2.1741e-01, 4.3514e-03, 2.5439e-04,  ..., 8.0046e-02,\n",
       "           8.0820e-04, 1.9936e-01],\n",
       "          [3.3516e-01, 8.0426e-04, 3.9987e-04,  ..., 1.8831e-03,\n",
       "           3.3739e-01, 3.1635e-01],\n",
       "          [4.9617e-01, 4.8851e-03, 4.2698e-03,  ..., 1.9006e-03,\n",
       "           2.3568e-03, 4.4968e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.4679e-01, 1.0306e-02, 2.0627e-02,  ..., 1.5926e-02,\n",
       "           2.8376e-02, 4.2086e-01],\n",
       "          [2.6998e-01, 1.6338e-02, 2.7682e-02,  ..., 2.0323e-02,\n",
       "           2.0992e-02, 2.7181e-01],\n",
       "          [2.5325e-01, 7.9299e-03, 1.1451e-02,  ..., 1.5978e-02,\n",
       "           2.0128e-02, 2.6267e-01],\n",
       "          ...,\n",
       "          [4.3379e-01, 3.7351e-03, 4.6707e-03,  ..., 2.9850e-02,\n",
       "           5.5368e-02, 4.4354e-01],\n",
       "          [4.6803e-01, 7.2007e-03, 2.8619e-03,  ..., 8.7384e-03,\n",
       "           1.9607e-02, 4.6858e-01],\n",
       "          [4.4884e-01, 9.9293e-03, 1.9758e-02,  ..., 1.5238e-02,\n",
       "           2.7022e-02, 4.2317e-01]],\n",
       "\n",
       "         [[4.8647e-01, 5.0834e-03, 2.4593e-03,  ..., 2.0439e-03,\n",
       "           5.7669e-03, 4.5849e-01],\n",
       "          [4.4078e-01, 1.8707e-02, 1.3342e-02,  ..., 5.1035e-03,\n",
       "           1.0152e-02, 4.3713e-01],\n",
       "          [3.3202e-01, 4.1441e-02, 2.8076e-02,  ..., 1.4539e-02,\n",
       "           4.5606e-02, 3.1918e-01],\n",
       "          ...,\n",
       "          [1.8260e-01, 5.8803e-02, 4.0843e-02,  ..., 1.1742e-02,\n",
       "           9.0892e-02, 1.8037e-01],\n",
       "          [1.6943e-01, 5.4621e-02, 5.9385e-02,  ..., 1.3404e-02,\n",
       "           8.1907e-02, 1.7202e-01],\n",
       "          [4.8595e-01, 5.1659e-03, 2.4917e-03,  ..., 2.0777e-03,\n",
       "           5.6977e-03, 4.5840e-01]],\n",
       "\n",
       "         [[4.7433e-01, 6.4334e-03, 1.4830e-02,  ..., 1.7200e-03,\n",
       "           5.0548e-03, 4.5878e-01],\n",
       "          [2.8329e-01, 6.7542e-02, 5.4257e-02,  ..., 6.2195e-02,\n",
       "           3.0566e-02, 2.7544e-01],\n",
       "          [3.6037e-01, 9.6286e-02, 3.8716e-02,  ..., 1.0379e-02,\n",
       "           7.8745e-03, 3.4821e-01],\n",
       "          ...,\n",
       "          [3.2229e-01, 2.0155e-01, 1.0837e-02,  ..., 7.0978e-03,\n",
       "           6.7217e-03, 3.1643e-01],\n",
       "          [3.7316e-01, 2.8501e-02, 1.4521e-02,  ..., 6.9387e-03,\n",
       "           3.1857e-02, 3.6201e-01],\n",
       "          [4.7424e-01, 6.2576e-03, 1.4807e-02,  ..., 1.6944e-03,\n",
       "           5.0370e-03, 4.5891e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.1392e-01, 1.7315e-02, 2.7090e-02,  ..., 6.1446e-03,\n",
       "           4.0042e-02, 4.0754e-01],\n",
       "          [4.6618e-01, 2.9783e-02, 1.9694e-02,  ..., 1.4836e-03,\n",
       "           3.0833e-03, 4.5980e-01],\n",
       "          [4.8745e-01, 1.2666e-02, 8.9341e-03,  ..., 6.8969e-04,\n",
       "           1.5201e-03, 4.7920e-01],\n",
       "          ...,\n",
       "          [3.1815e-01, 4.3400e-02, 1.9967e-02,  ..., 5.3612e-03,\n",
       "           4.9984e-03, 3.1271e-01],\n",
       "          [1.2816e-01, 3.4477e-02, 2.7849e-02,  ..., 1.4636e-02,\n",
       "           8.6406e-02, 1.2655e-01],\n",
       "          [4.1443e-01, 1.7259e-02, 2.6967e-02,  ..., 6.1481e-03,\n",
       "           3.9749e-02, 4.0804e-01]],\n",
       "\n",
       "         [[1.6975e-02, 5.7460e-02, 2.2630e-02,  ..., 4.5785e-02,\n",
       "           4.1408e-01, 1.6906e-02],\n",
       "          [3.3851e-01, 5.9579e-02, 2.1904e-01,  ..., 5.4969e-03,\n",
       "           1.4498e-03, 3.3354e-01],\n",
       "          [1.2859e-01, 7.3302e-01, 3.8562e-03,  ..., 9.8264e-05,\n",
       "           1.7959e-04, 1.2750e-01],\n",
       "          ...,\n",
       "          [4.2864e-01, 5.2897e-03, 1.1246e-03,  ..., 7.4476e-03,\n",
       "           3.3647e-02, 4.2473e-01],\n",
       "          [1.0585e-01, 1.0448e-01, 1.1161e-02,  ..., 3.8707e-01,\n",
       "           6.9226e-02, 1.0500e-01],\n",
       "          [1.7030e-02, 5.7637e-02, 2.2709e-02,  ..., 4.5809e-02,\n",
       "           4.1536e-01, 1.6961e-02]],\n",
       "\n",
       "         [[4.5292e-01, 1.8914e-03, 8.6097e-04,  ..., 1.4455e-03,\n",
       "           6.7441e-02, 4.4976e-01],\n",
       "          [4.4168e-01, 3.0773e-02, 3.4059e-02,  ..., 4.0009e-03,\n",
       "           1.2144e-03, 4.3343e-01],\n",
       "          [4.4695e-01, 1.6611e-02, 4.7116e-02,  ..., 9.9252e-03,\n",
       "           1.2324e-03, 4.3909e-01],\n",
       "          ...,\n",
       "          [4.4142e-01, 3.2129e-03, 9.8576e-03,  ..., 5.8464e-02,\n",
       "           3.1907e-03, 4.3488e-01],\n",
       "          [3.5360e-01, 2.1472e-02, 2.1443e-02,  ..., 2.0921e-02,\n",
       "           7.9653e-02, 3.5037e-01],\n",
       "          [4.5291e-01, 1.9177e-03, 8.6381e-04,  ..., 1.4608e-03,\n",
       "           6.7362e-02, 4.4974e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.1661e-02, 9.2714e-02, 6.3384e-02,  ..., 1.1069e-01,\n",
       "           1.9404e-01, 3.1372e-02],\n",
       "          [3.6949e-01, 3.0316e-02, 3.4489e-02,  ..., 1.7671e-02,\n",
       "           9.2314e-03, 3.6568e-01],\n",
       "          [3.7932e-01, 3.4281e-02, 1.3952e-02,  ..., 9.0681e-03,\n",
       "           5.7655e-03, 3.7465e-01],\n",
       "          ...,\n",
       "          [4.9153e-01, 3.9075e-04, 2.2390e-04,  ..., 2.4371e-03,\n",
       "           9.8696e-03, 4.8778e-01],\n",
       "          [3.8685e-01, 9.9146e-03, 1.1532e-02,  ..., 3.0759e-02,\n",
       "           1.0487e-01, 3.8496e-01],\n",
       "          [3.1976e-02, 9.3110e-02, 6.3485e-02,  ..., 1.1016e-01,\n",
       "           1.9359e-01, 3.1685e-02]],\n",
       "\n",
       "         [[5.3218e-02, 3.0153e-02, 6.5458e-02,  ..., 1.2608e-01,\n",
       "           3.1705e-01, 5.2901e-02],\n",
       "          [4.8793e-01, 1.6967e-02, 6.3741e-03,  ..., 3.4103e-04,\n",
       "           5.5427e-04, 4.8271e-01],\n",
       "          [4.5724e-01, 5.0129e-02, 3.0466e-02,  ..., 5.6207e-04,\n",
       "           1.3719e-03, 4.4987e-01],\n",
       "          ...,\n",
       "          [1.8635e-01, 1.1467e-02, 5.0849e-03,  ..., 9.9307e-03,\n",
       "           8.4559e-03, 1.8205e-01],\n",
       "          [1.2577e-01, 4.4075e-02, 1.5538e-02,  ..., 4.7510e-02,\n",
       "           7.5806e-02, 1.2375e-01],\n",
       "          [5.3181e-02, 2.9928e-02, 6.5060e-02,  ..., 1.2712e-01,\n",
       "           3.1776e-01, 5.2864e-02]],\n",
       "\n",
       "         [[1.5132e-01, 3.8853e-02, 2.9466e-02,  ..., 5.8886e-02,\n",
       "           1.8267e-01, 1.4838e-01],\n",
       "          [3.7071e-01, 8.5203e-03, 1.1146e-01,  ..., 4.9918e-03,\n",
       "           7.1427e-03, 3.6637e-01],\n",
       "          [4.0633e-01, 4.2367e-03, 6.2434e-03,  ..., 5.7370e-04,\n",
       "           3.6539e-03, 4.0226e-01],\n",
       "          ...,\n",
       "          [4.8064e-01, 1.9922e-04, 2.8276e-04,  ..., 1.2492e-03,\n",
       "           3.5687e-02, 4.7807e-01],\n",
       "          [3.7656e-01, 3.5173e-02, 8.8520e-03,  ..., 4.2704e-02,\n",
       "           7.5269e-02, 3.7690e-01],\n",
       "          [1.5221e-01, 3.8805e-02, 2.9372e-02,  ..., 5.8293e-02,\n",
       "           1.8263e-01, 1.4925e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained('rbt3', num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.4554,  0.2853, -0.1562, -0.2745,  0.5057, -0.0642, -0.2172, -0.5352,\n",
       "          0.2081, -0.3353]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
